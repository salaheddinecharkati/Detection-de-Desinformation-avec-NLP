# Detection-de-Desinformation-avec-NLP

---

## üìù Introduction

La d√©sinformation repr√©sente aujourd'hui un d√©fi majeur, en particulier sur les r√©seaux sociaux o√π les fake news se propagent rapidement et influencent l'opinion publique.  
Ce projet s'inscrit dans le champ du traitement automatique du langage naturel (NLP) et vise √† d√©velopper un syst√®me de d√©tection automatique de fausses informations bas√© sur l'utilisation du mod√®le BERT.  
L'objectif est de proposer une approche efficace permettant d'identifier des articles douteux et d'assister les efforts de v√©rification des faits.

---

## üéØ Objectifs et champ d'application

- D√©tecter automatiquement les fake news √† partir d'articles textuels.
- Fournir une aide √† la v√©rification des faits pour les journalistes et chercheurs.
- Exp√©rimenter l'utilisation d'un mod√®le pr√©-entra√Æn√© BERT pour la classification de texte.

---

## ü§ñ Pr√©sentation du mod√®le BERT

BERT (Bidirectional Encoder Representations from Transformers) est un mod√®le NLP d√©velopp√© par Google.  
- Architecture bas√©e sur les Transformers.  
- Lecture **bidirectionnelle** des s√©quences de texte pour une compr√©hension fine du contexte.  
- Pr√©-entra√Æn√© sur une grande quantit√© de donn√©es textuelles.  
- Adaptable √† des t√¢ches sp√©cifiques comme la classification de texte.  

Dans ce projet, BERT est utilis√© pour diff√©rencier les fake news des articles fiables.

---

## üìä Donn√©es utilis√©es

### ISOT Fake and Real News Dataset
- Contenu : environ 44 000 articles r√©partis en deux classes : FAKE et REAL.  
- Fichiers : `Fake.csv` (fausses informations) et `True.csv` (informations v√©rifi√©es).  
- Colonnes principales : `title`, `text`, `subject`, `date`.  
- Une colonne `label` a √©t√© ajout√©e pour la classification (`0 = FAKE`, `1 = REAL`) et encod√©e avec `LabelEncoder`.

### Pr√©traitement des textes
- Utilisation du tokenizer BERT.
- Troncature et padding √† une longueur maximale de 128 tokens.
- G√©n√©ration des `input_ids` et `attention_mask`.
- S√©paration des donn√©es :
  - Train : 80%
  - Validation : 10%
  - Test : 10%
- Stratification selon les classes.

---

## ‚öôÔ∏è M√©thodologie

### Entra√Ænement du mod√®le
- Mod√®le : `BertForSequenceClassification` (`num_labels=2`)
- Entra√Ænement avec la classe `Trainer` de Hugging Face.
- Hyperparam√®tres :
  - √âpoques : 4
  - Batch size : 16
  - Optimiseur : AdamW
- S√©lection du meilleur mod√®le selon le **F1-score**.

### √âvaluation du mod√®le
- M√©triques calcul√©es : accuracy, pr√©cision, rappel, F1-score.
- R√©sultats sur le jeu de test :
  - Loss : 0.0032
  - Accuracy : 99.95%
  - Precision : 100%
  - Recall : 99.91%
  - F1-score : 99.95%

### Matrice de confusion
|            | Pr√©dit FAKE | Pr√©dit REAL |
|------------|------------|------------|
| R√©el FAKE  | 2348       | 0          |
| R√©el REAL  | 2          | 2140       |

- Accuracy : 99.96%

---

## ‚úÖ Conclusion

Le projet d√©montre qu'un mod√®le BERT bien entra√Æn√© peut d√©tecter efficacement les fake news avec une pr√©cision √©lev√©e.  
Cette approche peut √™tre int√©gr√©e dans des syst√®mes d'alerte automatis√©s pour limiter la propagation de la d√©sinformation sur les plateformes num√©riques.
